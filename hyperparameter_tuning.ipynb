{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44156ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from cluster.RayJobManager import RayJobManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64fa1057",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "RAY_ADDRESS  = \"http://10.254.31.202:8265\"\n",
    "#RAY_ADDRESS  = \"local\"\n",
    "ENTRYPOINT   = \"python3 cluster/tune_grid.py\"\n",
    "WORKING_DIR  = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN-Ray/\"\n",
    "PIP = {\n",
    "    \"packages\": [\n",
    "        \"torch\",\n",
    "        \"ray[tune]\",\n",
    "        \"git+https://github.com/EmanueleCoradin/TrackSelectorDNN.git@main\"\n",
    "    ],\n",
    "    \"pip_check\": False,\n",
    "    \"pip_install_options\": [\"--vvv\"]\n",
    "}\n",
    "\n",
    "ray_manager = RayJobManager(ray_address=RAY_ADDRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515aa0af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 15:27:58,492\tINFO dashboard_sdk.py:338 -- Uploading package gcs://_ray_pkg_9902c00d17eb191f.zip.\n",
      "2025-11-04 15:27:58,495\tINFO packaging.py:588 -- Creating a file package for local module '/eos/user/e/ecoradin/GitHub/TrackSelectorDNN-Ray/'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted Ray job: raysubmit_h4wNperMfe39VG8A\n",
      "Job status: PENDING\n",
      "Job status: RUNNING\n",
      "Job status: RUNNING\n",
      "Job status: RUNNING\n",
      "Job status: RUNNING\n",
      "Job status: RUNNING\n",
      "Job status: RUNNING\n",
      "Job status: SUCCEEDED\n",
      "\n",
      "--- Job Logs ---\n",
      "2025-11-04 07:27:59,329\tINFO job_manager.py:568 -- Runtime env is setting up.\n",
      "2025-11-04 07:28:01,875\tINFO worker.py:1692 -- Using address 10.100.192.237:6379 set in the environment variable RAY_ADDRESS\n",
      "2025-11-04 07:28:01,877\tINFO worker.py:1833 -- Connecting to existing Ray cluster at address: 10.100.192.237:6379...\n",
      "2025-11-04 07:28:01,887\tINFO worker.py:2004 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m10.100.192.237:8265 \u001b[39m\u001b[22m\n",
      "/home/ray/anaconda3/lib/python3.9/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "2025-11-04 07:28:01,897\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "╭──────────────────────────────────────────────────────────────────╮\n",
      "│ Configuration for experiment     trainable_2025-11-04_07-28-01   │\n",
      "├──────────────────────────────────────────────────────────────────┤\n",
      "│ Search algorithm                 BasicVariantGenerator           │\n",
      "│ Scheduler                        FIFOScheduler                   │\n",
      "│ Number of trials                 3                               │\n",
      "╰──────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "View detailed results here: /home/ray/ray_results/trainable_2025-11-04_07-28-01\n",
      "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-11-04_02-10-30_183272_1/artifacts/2025-11-04_07-28-01/trainable_2025-11-04_07-28-01/driver_artifacts`\n",
      "\n",
      "Trial status: 3 PENDING\n",
      "Current time: 2025-11-04 07:28:02. Total running time: 0s\n",
      "Logical resource usage: 0/2 CPUs, 0/2 GPUs (0.0/2.0 accelerator_type:H100)\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name              status       latent_dim   pooling_type       netA_hidden_layers     netB_hidden_layers            lr     weight_decay │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ trainable_d9cdf_00000   PENDING              32   mean                                5                      5   0.00121713       1.21756e-05 │\n",
      "│ trainable_d9cdf_00001   PENDING              32   sum                                 3                      4   0.0042677        7.8665e-05  │\n",
      "│ trainable_d9cdf_00002   PENDING              16   sum                                 2                      3   0.000587133      0.00123117  │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "Trial trainable_d9cdf_00000 started with configuration:\n",
      "╭─────────────────────────────────────────────────────────────╮\n",
      "│ Trial trainable_d9cdf_00000 config                          │\n",
      "├─────────────────────────────────────────────────────────────┤\n",
      "│ batch_size                                               64 │\n",
      "│ dataset_type                                          dummy │\n",
      "│ epochs                                                   10 │\n",
      "│ hit_input_dim                                             4 │\n",
      "│ latent_dim                                               32 │\n",
      "│ lr                                                  0.00122 │\n",
      "│ max_hits                                                 15 │\n",
      "│ n_tracks                                               2000 │\n",
      "│ netA_activation                                        silu │\n",
      "│ netA_batchnorm                                         True │\n",
      "│ netA_hidden_dim                                          32 │\n",
      "│ netA_hidden_layers                                        5 │\n",
      "│ netB_activation                                        silu │\n",
      "│ netB_batchnorm                                         True │\n",
      "│ netB_hidden_dim                                          64 │\n",
      "│ netB_hidden_layers                                        5 │\n",
      "│ pooling_type                                           mean │\n",
      "│ track_feat_dim                                            4 │\n",
      "│ train_path                             ...d/tracks_train.pt │\n",
      "│ val_fraction                                            0.2 │\n",
      "│ weight_decay                                        0.00001 │\n",
      "╰─────────────────────────────────────────────────────────────╯\n",
      "\n",
      "Trial trainable_d9cdf_00001 started with configuration:\n",
      "╭─────────────────────────────────────────────────────────────╮\n",
      "│ Trial trainable_d9cdf_00001 config                          │\n",
      "├─────────────────────────────────────────────────────────────┤\n",
      "│ batch_size                                               64 │\n",
      "│ dataset_type                                          dummy │\n",
      "│ epochs                                                   10 │\n",
      "│ hit_input_dim                                             4 │\n",
      "│ latent_dim                                               32 │\n",
      "│ lr                                                  0.00427 │\n",
      "│ max_hits                                                 15 │\n",
      "│ n_tracks                                               2000 │\n",
      "│ netA_activation                                        silu │\n",
      "│ netA_batchnorm                                         True │\n",
      "│ netA_hidden_dim                                          32 │\n",
      "│ netA_hidden_layers                                        3 │\n",
      "│ netB_activation                                        silu │\n",
      "│ netB_batchnorm                                         True │\n",
      "│ netB_hidden_dim                                          64 │\n",
      "│ netB_hidden_layers                                        4 │\n",
      "│ pooling_type                                            sum │\n",
      "│ track_feat_dim                                            4 │\n",
      "│ train_path                             ...d/tracks_train.pt │\n",
      "│ val_fraction                                            0.2 │\n",
      "│ weight_decay                                        0.00008 │\n",
      "╰─────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 1/10] train_loss=0.3148, val_loss=0.5003, val_acc=0.7900\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 2/10] train_loss=0.0835, val_loss=0.0667, val_acc=0.9825\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 3/10] train_loss=0.0541, val_loss=0.0362, val_acc=0.9875\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 4/10] train_loss=0.0351, val_loss=0.0400, val_acc=0.9900\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 5/10] train_loss=0.0301, val_loss=0.0471, val_acc=0.9850\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 6/10] train_loss=0.0211, val_loss=0.0470, val_acc=0.9875\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 7/10] train_loss=0.0241, val_loss=0.0163, val_acc=0.9975\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 8/10] train_loss=0.0262, val_loss=0.0229, val_acc=0.9975\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 9/10] train_loss=0.0137, val_loss=0.0311, val_acc=0.9875\n",
      "\n",
      "Trial trainable_d9cdf_00000 completed after 11 iterations at 2025-11-04 07:28:07. Total running time: 5s\n",
      "╭────────────────────────────────────────────────╮\n",
      "│ Trial trainable_d9cdf_00000 result             │\n",
      "├────────────────────────────────────────────────┤\n",
      "│ checkpoint_dir_name                            │\n",
      "│ time_this_iter_s                       0.02021 │\n",
      "│ time_total_s                           2.34657 │\n",
      "│ training_iteration                          11 │\n",
      "│ val_loss                               0.01154 │\n",
      "╰────────────────────────────────────────────────╯\n",
      "\u001b[36m(trainable pid=165402, ip=10.100.240.14)\u001b[0m [Epoch 10/10] train_loss=0.0097, val_loss=0.0115, val_acc=0.9975\n",
      "\n",
      "Trial trainable_d9cdf_00002 started with configuration:\n",
      "╭─────────────────────────────────────────────────────────────╮\n",
      "│ Trial trainable_d9cdf_00002 config                          │\n",
      "├─────────────────────────────────────────────────────────────┤\n",
      "│ batch_size                                               64 │\n",
      "│ dataset_type                                          dummy │\n",
      "│ epochs                                                   10 │\n",
      "│ hit_input_dim                                             4 │\n",
      "│ latent_dim                                               16 │\n",
      "│ lr                                                  0.00059 │\n",
      "│ max_hits                                                 15 │\n",
      "│ n_tracks                                               2000 │\n",
      "│ netA_activation                                        silu │\n",
      "│ netA_batchnorm                                         True │\n",
      "│ netA_hidden_dim                                          32 │\n",
      "│ netA_hidden_layers                                        2 │\n",
      "│ netB_activation                                        silu │\n",
      "│ netB_batchnorm                                         True │\n",
      "│ netB_hidden_dim                                          64 │\n",
      "│ netB_hidden_layers                                        3 │\n",
      "│ pooling_type                                            sum │\n",
      "│ track_feat_dim                                            4 │\n",
      "│ train_path                             ...d/tracks_train.pt │\n",
      "│ val_fraction                                            0.2 │\n",
      "│ weight_decay                                        0.00123 │\n",
      "╰─────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 1/10] train_loss=0.4539, val_loss=0.4354, val_acc=0.9500\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 2/10] train_loss=0.2246, val_loss=0.1867, val_acc=0.9725\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 3/10] train_loss=0.1512, val_loss=0.1356, val_acc=0.9775\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 4/10] train_loss=0.1028, val_loss=0.0908, val_acc=0.9925\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 5/10] train_loss=0.0819, val_loss=0.0752, val_acc=0.9950\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 6/10] train_loss=0.0634, val_loss=0.0569, val_acc=0.9950\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 7/10] train_loss=0.0480, val_loss=0.0467, val_acc=0.9975\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 8/10] train_loss=0.0406, val_loss=0.0419, val_acc=0.9975\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 9/10] train_loss=0.0369, val_loss=0.0314, val_acc=1.0000\n",
      "\n",
      "Trial trainable_d9cdf_00002 completed after 11 iterations at 2025-11-04 07:28:12. Total running time: 10s\n",
      "╭────────────────────────────────────────────────╮\n",
      "│ Trial trainable_d9cdf_00002 result             │\n",
      "├────────────────────────────────────────────────┤\n",
      "│ checkpoint_dir_name                            │\n",
      "│ time_this_iter_s                       0.02449 │\n",
      "│ time_total_s                            2.0481 │\n",
      "│ training_iteration                          11 │\n",
      "│ val_loss                               0.04151 │\n",
      "╰────────────────────────────────────────────────╯\n",
      "\u001b[36m(trainable pid=165740, ip=10.100.240.14)\u001b[0m [Epoch 10/10] train_loss=0.0394, val_loss=0.0415, val_acc=0.9925\n",
      "\n",
      "Trial status: 2 TERMINATED | 1 RUNNING\n",
      "Current time: 2025-11-04 07:28:32. Total running time: 30s\n",
      "Logical resource usage: 1.0/2 CPUs, 0/2 GPUs (0.0/2.0 accelerator_type:H100)\n",
      "Current best trial: d9cdf_00000 with val_loss=0.011537710763514042 and params={'hit_input_dim': 4, 'track_feat_dim': 4, 'latent_dim': 32, 'pooling_type': 'mean', 'netA_hidden_dim': 32, 'netA_hidden_layers': 5, 'netA_batchnorm': True, 'netA_activation': 'silu', 'netB_hidden_dim': 64, 'netB_hidden_layers': 5, 'netB_batchnorm': True, 'netB_activation': 'silu', 'lr': 0.001217134998714413, 'epochs': 10, 'batch_size': 64, 'dataset_type': 'dummy', 'train_path': 'data/processed/tracks_train.pt', 'n_tracks': 2000, 'max_hits': 15, 'val_fraction': 0.2, 'weight_decay': 1.2175566394466884e-05}\n",
      "╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name              status         latent_dim   pooling_type       netA_hidden_layers     netB_hidden_layers            lr     weight_decay     iter     total time (s)     val_loss │\n",
      "├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ trainable_d9cdf_00001   RUNNING                32   sum                                 3                      4   0.0042677        7.8665e-05                                           │\n",
      "│ trainable_d9cdf_00000   TERMINATED             32   mean                                5                      5   0.00121713       1.21756e-05       11            2.34657    0.0115377 │\n",
      "│ trainable_d9cdf_00002   TERMINATED             16   sum                                 2                      3   0.000587133      0.00123117        11            2.0481     0.041509  │\n",
      "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 1/10] train_loss=0.1890, val_loss=0.1433, val_acc=0.9400\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 2/10] train_loss=0.0566, val_loss=0.0386, val_acc=0.9850\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 3/10] train_loss=0.0543, val_loss=0.1821, val_acc=0.9575\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 4/10] train_loss=0.0583, val_loss=0.0386, val_acc=0.9800\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 5/10] train_loss=0.0313, val_loss=0.0260, val_acc=0.9875\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 6/10] train_loss=0.0223, val_loss=0.0420, val_acc=0.9850\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 7/10] train_loss=0.0309, val_loss=0.0331, val_acc=0.9875\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 8/10] train_loss=0.0219, val_loss=0.0441, val_acc=0.9825\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 9/10] train_loss=0.0295, val_loss=0.0565, val_acc=0.9825\n",
      "\u001b[36m(trainable pid=128599, ip=10.100.133.99)\u001b[0m [Epoch 10/10] train_loss=0.0184, val_loss=0.0627, val_acc=0.9850\n",
      "\n",
      "Trial trainable_d9cdf_00001 completed after 11 iterations at 2025-11-04 07:29:01. Total running time: 58s\n",
      "╭────────────────────────────────────────────────╮\n",
      "│ Trial trainable_d9cdf_00001 result             │\n",
      "├────────────────────────────────────────────────┤\n",
      "│ checkpoint_dir_name                            │\n",
      "│ time_this_iter_s                       10.3966 │\n",
      "│ time_total_s                           56.0011 │\n",
      "│ training_iteration                          11 │\n",
      "│ val_loss                               0.06274 │\n",
      "╰────────────────────────────────────────────────╯\n",
      "2025-11-04 07:29:01,128\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/ray/ray_results/trainable_2025-11-04_07-28-01' in 0.0030s.\n",
      "\n",
      "Trial status: 3 TERMINATED\n",
      "Current time: 2025-11-04 07:29:01. Total running time: 58s\n",
      "Logical resource usage: 1.0/2 CPUs, 0/2 GPUs (0.0/2.0 accelerator_type:H100)\n",
      "Current best trial: d9cdf_00000 with val_loss=0.011537710763514042 and params={'hit_input_dim': 4, 'track_feat_dim': 4, 'latent_dim': 32, 'pooling_type': 'mean', 'netA_hidden_dim': 32, 'netA_hidden_layers': 5, 'netA_batchnorm': True, 'netA_activation': 'silu', 'netB_hidden_dim': 64, 'netB_hidden_layers': 5, 'netB_batchnorm': True, 'netB_activation': 'silu', 'lr': 0.001217134998714413, 'epochs': 10, 'batch_size': 64, 'dataset_type': 'dummy', 'train_path': 'data/processed/tracks_train.pt', 'n_tracks': 2000, 'max_hits': 15, 'val_fraction': 0.2, 'weight_decay': 1.2175566394466884e-05}\n",
      "╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name              status         latent_dim   pooling_type       netA_hidden_layers     netB_hidden_layers            lr     weight_decay     iter     total time (s)     val_loss │\n",
      "├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ trainable_d9cdf_00000   TERMINATED             32   mean                                5                      5   0.00121713       1.21756e-05       11            2.34657    0.0115377 │\n",
      "│ trainable_d9cdf_00001   TERMINATED             32   sum                                 3                      4   0.0042677        7.8665e-05        11           56.0011     0.0627386 │\n",
      "│ trainable_d9cdf_00002   TERMINATED             16   sum                                 2                      3   0.000587133      0.00123117        11            2.0481     0.041509  │\n",
      "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "Best config found:\n",
      "{'hit_input_dim': 4, 'track_feat_dim': 4, 'latent_dim': 32, 'pooling_type': 'mean', 'netA_hidden_dim': 32, 'netA_hidden_layers': 5, 'netA_batchnorm': True, 'netA_activation': 'silu', 'netB_hidden_dim': 64, 'netB_hidden_layers': 5, 'netB_batchnorm': True, 'netB_activation': 'silu', 'lr': 0.001217134998714413, 'epochs': 10, 'batch_size': 64, 'dataset_type': 'dummy', 'train_path': 'data/processed/tracks_train.pt', 'n_tracks': 2000, 'max_hits': 15, 'val_fraction': 0.2, 'weight_decay': 1.2175566394466884e-05}\n",
      "Best checkpoint path: None\n",
      "\n",
      "Job completed successfully!\n"
     ]
    }
   ],
   "source": [
    "job_id = ray_manager.submit_job(\n",
    "    entrypoint=ENTRYPOINT,\n",
    "    runtime_env={\n",
    "        \"working_dir\": WORKING_DIR, \n",
    "        \"pip\": PIP, \n",
    "    }\n",
    "    \n",
    ")\n",
    "\n",
    "ray_manager.wait_until_done(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cc47c8-8891-4741-a3ba-e0fa99ae6733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: TrackSelectorDNN 0.1\n",
      "Uninstalling TrackSelectorDNN-0.1:\n",
      "  Successfully uninstalled TrackSelectorDNN-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y TrackSelectorDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358bb236-b69c-49bc-b322-cca23f50566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///eos/home-i03/e/ecoradin/GitHub/TrackSelectorDNN\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from TrackSelectorDNN==0.1) (2.3.1+cu121)\n",
      "Requirement already satisfied: pydantic>=2.0 in /eos/user/e/ecoradin/.local/lib/python3.11/site-packages (from TrackSelectorDNN==0.1) (2.12.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /eos/user/e/ecoradin/.local/lib/python3.11/site-packages (from pydantic>=2.0->TrackSelectorDNN==0.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /eos/user/e/ecoradin/.local/lib/python3.11/site-packages (from pydantic>=2.0->TrackSelectorDNN==0.1) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /eos/user/e/ecoradin/.local/lib/python3.11/site-packages (from pydantic>=2.0->TrackSelectorDNN==0.1) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /eos/user/e/ecoradin/.local/lib/python3.11/site-packages (from pydantic>=2.0->TrackSelectorDNN==0.1) (0.4.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->TrackSelectorDNN==0.1) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->TrackSelectorDNN==0.1) (12.1.105)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->TrackSelectorDNN==0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->TrackSelectorDNN==0.1) (1.3.0)\n",
      "Installing collected packages: TrackSelectorDNN\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of TrackSelectorDNN==0.1 from file:///eos/home-i03/e/ecoradin/GitHub/TrackSelectorDNN (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py develop for TrackSelectorDNN\n",
      "Successfully installed TrackSelectorDNN-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ../TrackSelectorDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb7e5d8-5672-45dd-a26c-299fd873f100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-11-04 16:13:18</td></tr>\n",
       "<tr><td>Running for: </td><td>00:25:03.62        </td></tr>\n",
       "<tr><td>Memory:      </td><td>68.7/1007.5 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/30 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:H100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  latent_dim</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  netA_hidden_layers</th><th style=\"text-align: right;\">  netB_hidden_layers</th><th>pooling_type  </th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_ac5fb_00000</td><td>TERMINATED</td><td>188.185.190.154:11198</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">8.41169e-05</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                   1</td><td>sum           </td><td style=\"text-align: right;\">   2.00408e-05</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         1488.16</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">   0.0133019</td><td style=\"text-align: right;\"> 0.0104716</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 1/10] train_loss=0.1704, val_loss=0.0606, val_acc=0.9944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m /eos/user/e/ecoradin/.local/lib/python3.11/site-packages/ray/train/_internal/session.py:792: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(trainable pid=11198)\u001b[0m   _log_deprecation_warning(\n",
      "\u001b[36m(trainable pid=11198)\u001b[0m /eos/user/e/ecoradin/.local/lib/python3.11/site-packages/ray/tune/trainable/trainable_fn_utils.py:41: RayDeprecationWarning: The `Checkpoint` class should be imported from `ray.tune` when passing it to `ray.tune.report` in a Tune function. Please update your imports. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\n",
      "\u001b[36m(trainable pid=11198)\u001b[0m   _log_deprecation_warning(\n",
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 2/10] train_loss=0.0471, val_loss=0.0291, val_acc=0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 3/10] train_loss=0.0274, val_loss=0.0194, val_acc=0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 4/10] train_loss=0.0210, val_loss=0.0169, val_acc=0.9955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000003)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 5/10] train_loss=0.0179, val_loss=0.0131, val_acc=0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 6/10] train_loss=0.0170, val_loss=0.0126, val_acc=0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 7/10] train_loss=0.0151, val_loss=0.0125, val_acc=0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000006)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 8/10] train_loss=0.0144, val_loss=0.0116, val_acc=0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 9/10] train_loss=0.0142, val_loss=0.0109, val_acc=0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m [Epoch 10/10] train_loss=0.0133, val_loss=0.0105, val_acc=0.9967\n",
      "\u001b[36m(trainable pid=11198)\u001b[0m [DEBUG] Final report to Ray: /eos/user/e/ecoradin/GitHub/TrackSelectorDNN/runs/2025-11-04_15-48-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000009)\n",
      "\u001b[36m(trainable pid=11198)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000010)\n",
      "2025-11-04 16:13:18,311\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52' in 0.2468s.\n",
      "2025-11-04 16:13:18,326\tINFO tune.py:1041 -- Total run time: 1504.18 seconds (1503.38 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Uncomment to run locally\n",
    "from ray import tune\n",
    "from TrackSelectorDNN.configs.schema import load_config\n",
    "from TrackSelectorDNN.tune.trainable import trainable\n",
    "\n",
    "base_cfg = load_config(\"base.yaml\").model_dump()\n",
    "\n",
    "search_space = {\n",
    "    **base_cfg,  # include all validated defaults\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"latent_dim\": tune.choice([16, 32, 64]),\n",
    "    \"pooling_type\": tune.choice([\"sum\", \"mean\", \"softmax\"]),\n",
    "    \"netA_hidden_layers\": tune.choice([1, 2, 3, 4, 5]),\n",
    "    \"netB_hidden_layers\": tune.choice([1, 2, 3, 4, 5]),\n",
    "}\n",
    "\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable,\n",
    "    param_space=search_space,\n",
    "    tune_config=tune.TuneConfig(metric=\"val_loss\", mode=\"min\", num_samples=1),\n",
    ")\n",
    "\n",
    "results = tuner.fit()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885b87e7-96bd-4c87-9c69-445051504d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config found:\n",
      "{'hit_input_dim': 10, 'track_feat_dim': 16, 'latent_dim': 64, 'pooling_type': 'sum', 'netA_hidden_dim': 32, 'netA_hidden_layers': 3, 'netA_batchnorm': True, 'netA_activation': 'silu', 'netB_hidden_dim': 64, 'netB_hidden_layers': 1, 'netB_batchnorm': True, 'netB_activation': 'silu', 'lr': 8.411694872074715e-05, 'epochs': 10, 'batch_size': 64, 'dataset_type': 'dummy', 'dummy_load_path': '/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/dummy_dataset.pt', 'train_path': 'data/processed/tracks_train.pt', 'n_tracks': 100000, 'max_hits': 15, 'val_fraction': 0.2, 'weight_decay': 2.0040837755536215e-05}\n",
      "Best checkpoint path: Checkpoint(filesystem=local, path=/eos/user/e/ecoradin/ray_results/trainable_2025-11-04_15-47-52/trainable_ac5fb_00000_0_latent_dim=64,lr=0.0001,netA_hidden_layers=3,netB_hidden_layers=1,pooling_type=sum,weight_decay=0.0000_2025-11-04_15-48-14/checkpoint_000010)\n"
     ]
    }
   ],
   "source": [
    "best_result = results.get_best_result(metric=\"val_loss\", mode=\"min\")\n",
    "\n",
    "print(\"Best config found:\")\n",
    "print(best_result.config)\n",
    "\n",
    "best_ckpt_dir = best_result.checkpoint\n",
    "print(\"Best checkpoint path:\", best_ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7770d8f5-77b0-45f7-9980-00fd1699dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: /eos/user/e/ecoradin/GitHub/TrackSelectorDNN/runs/2025-11-04_15-48-29/best_model.pt\n",
      "Best val_loss: 0.010471555917942896\n",
      "Best config file: /eos/user/e/ecoradin/GitHub/TrackSelectorDNN/runs/2025-11-04_15-48-29/config.yaml\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrackSelectorDNN.models.track_classifier.TrackClassifier() argument after ** must be a mapping, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest config file:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_config)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m model \u001b[38;5;241m=\u001b[39m TrackClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_config)\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(best_ckpt_path))\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mTypeError\u001b[0m: TrackSelectorDNN.models.track_classifier.TrackClassifier() argument after ** must be a mapping, not str"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from TrackSelectorDNN.models.track_classifier import TrackClassifier\n",
    "\n",
    "run_root = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/runs\"\n",
    "best_val = float(\"inf\")\n",
    "best_ckpt_path = None\n",
    "best_config = None\n",
    "\n",
    "for trial_name in os.listdir(run_root):\n",
    "    trial_dir = os.path.join(run_root, trial_name)\n",
    "    metrics_file = os.path.join(trial_dir, \"best_metrics.json\")\n",
    "    ckpt_file = os.path.join(trial_dir, \"best_model.pt\")\n",
    "\n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "        if metrics[\"val_loss\"] < best_val:\n",
    "            best_val = metrics[\"val_loss\"]\n",
    "            best_ckpt_path = ckpt_file\n",
    "            # optionally save config\n",
    "            config_file = os.path.join(trial_dir, \"config.yaml\")\n",
    "            best_config = config_file if os.path.exists(config_file) else None\n",
    "\n",
    "print(\"Best checkpoint:\", best_ckpt_path)\n",
    "print(\"Best val_loss:\", best_val)\n",
    "print(\"Best config file:\", best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489c0e7-e76c-47aa-ac46-bb09a58f8743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
